------------------------------------------------
For training:
1. Data Preparation
   |
2. Data Augmentation
   |
3. Model Architecture
   |--- 3.1 Load & Preprocess Data
   |--- 3.2 Split Dataset
   |--- 3.3 Augmented Data for Training
   |--- 3.4 Define Model Architecture & Compilation
   |
4. Train Model
   |--- 4.1 Model Training
   |--- 4.2 Trained Model Parameters
   |--- 4.3 Model Evaluation & Performance Metrics
   |
5. Save Trained Model
   |--- 5.1 Save Model Checkpoint
   |--- 5.2 Save Performance Metrics
   |--- 5.3 End of Training Process

...................................................................
Description of the above diagram:

1) Data Preparation:

Load & Preprocess Data: Load the dataset and preprocess it if necessary. Split the dataset into training and validation sets.
Data Augmentation:

2) Augmented Data for Training: Apply data augmentation techniques to the training dataset to increase its diversity and improve model generalization.
Model:

3) Define Model Architecture & Compilation: Define the architecture of the neural network model and compile it with specified loss function, optimizer, and metrics.
Model Training:

4) Train Model: Train the compiled model using the augmented training data. This step involves iteratively updating the model parameters to minimize the training loss.
Model Evaluation:

5) Model Evaluation & Performance Metrics: Evaluate the trained model's performance on the validation dataset. Compute various performance metrics such as accuracy, precision, recall, etc.
Save Model:

6) Save Trained Model: Save the trained model's weights and architecture to disk for future use. Optionally, save checkpoints during training to resume training from a specific point.
End of Training Process:

7) Save Performance Metrics: Save the performance metrics obtained during model evaluation. This marks the end of the training process.

.............................................................................

Parameters used while training the model:

Here are all the parameters used to train the model:

1. **Data Preparation**:
   - `data.csv`: The file containing the dataset.
   - `test_size`: The proportion of the dataset to include in the test split.
   
2. **Data Augmentation**:
   - `rotation_range`: Degrees range for random rotations applied to the images.
   - `zoom_range`: Range for random zoom applied to the images.
   - `width_shift_range`: Range for random horizontal shifts applied to the images.
   - `height_shift_range`: Range for random vertical shifts applied to the images.
   - `horizontal_flip`: Boolean indicating whether to randomly flip images horizontally.
   - `vertical_flip`: Boolean indicating whether to randomly flip images vertically.

3. **Model Architecture**:
   - `Conv2D`: Convolutional layers with 32, 64, and 128 filters, respectively, each with a 3x3 kernel size and ReLU activation function.
   - `BatchNormalization`: Batch normalization layers after each convolutional layer.
   - `MaxPooling2D`: Max pooling layers with a 2x2 pool size.
   - `Dense`: Fully connected layers with 256, 128, and 64 units, respectively, with ReLU activation function.
   - `Dropout`: Dropout layers with a dropout rate of 0.5 after the first two Dense layers.
   - `softmax`: Activation function for the output layer, providing probabilities for each class.

4. **Model Compilation**:
   - `optimizer`: Adam optimizer.
   - `loss`: Sparse categorical cross-entropy loss function.
   - `metrics`: Accuracy metric for model evaluation.

5. **Callbacks**:
   - `EarlyStopping`: Monitor validation loss and stop training if no improvement after a certain number of epochs (patience).
   - `ReduceLROnPlateau`: Reduce learning rate when a metric has stopped improving.

6. **Model Training**:
   - `epochs`: Number of epochs for training.
   - `batch_size`: Number of samples per gradient update.

7. **Saving Model**:
   - `label_encoder.pkl`: Saved LabelEncoder object used for encoding target labels.
   - `accuracy_loss_plot.png`: Saved plot showing model accuracy and loss over epochs.
   - `ocr_model_new.h5`: Saved trained model in HDF5 format.

These parameters collectively define the entire training pipeline for your model.
..............................................................................


Values of parameters used in the model:

Certainly! Here are the parameters used in your model training code along with their corresponding values:

1. **Data Augmentation Parameters**:
   - `rotation_range`: 10
   - `zoom_range`: 0.1
   - `width_shift_range`: 0.1
   - `height_shift_range`: 0.1
   - `horizontal_flip`: True
   - `vertical_flip`: False

2. **Model Architecture Parameters**:
   - Convolutional Layers:
     - First Conv2D layer:
       - Filters: 32
       - Kernel Size: (3, 3)
       - Activation Function: ReLU
       - Kernel Regularization (L2): 0.001
     - Second Conv2D layer:
       - Filters: 64
       - Kernel Size: (3, 3)
       - Activation Function: ReLU
       - Kernel Regularization (L2): 0.001
     - Third Conv2D layer:
       - Filters: 128
       - Kernel Size: (3, 3)
       - Activation Function: ReLU
       - Kernel Regularization (L2): 0.001
   - Pooling Layers:
     - MaxPooling2D layer after each Conv2D layer with pool size (2, 2).
   - Dense Layers:
     - First Dense layer: Units: 256, Activation Function: ReLU, Dropout: 0.5, Kernel Regularization (L2): 0.001
     - Second Dense layer: Units: 128, Activation Function: ReLU, Dropout: 0.5, Kernel Regularization (L2): 0.001
     - Third Dense layer: Units: 64, Activation Function: ReLU, Kernel Regularization (L2): 0.001
     - Output Dense layer: Units: Number of unique labels in the dataset, Activation Function: Softmax

3. **Model Compilation Parameters**:
   - Optimizer: Adam
   - Loss Function: Sparse Categorical Crossentropy
   - Metrics: Accuracy

4. **Model Training Parameters**:
   - Batch Size: 32
   - Number of Epochs: 50
   - Early Stopping:
     - Monitor: Validation Loss
     - Patience: 3 epochs
   - Reduce LR on Plateau:
     - Monitor: Validation Accuracy
     - Patience: 2 epochs
     - Verbose: 1
     - Factor: 0.5
     - Minimum Learning Rate: 0.00001

5. **Saving Parameters**:
   - Label Encoder: Saved as 'label_encoder.pkl'
   - Model: Saved as 'ocr_model_new.h5'
   - Accuracy and Loss Plot: Saved as 'accuracy_loss_plot.png'

These are all the parameters and their corresponding values used in your model training code.

....................................................................................

-----------------------------------------------------
For Prediction:
1. Receive Image for Prediction
   |
2. Image Preprocessing
   |
3. Load Trained Model & Label Encoder
   |
4. Resize Image & Preprocess
   |
5. Model Prediction
   |
6. Convert Prediction to Class
   |
7. Return Prediction

Description:

1) Receive Image for Prediction: FastAPI receives an image file for prediction.

2) Image Preprocessing: The uploaded image is preprocessed (resized to 32x32, converted to grayscale, and inverted) before feeding it to the model.

3) Load Trained Model & Label Encoder: The trained model and label encoder are loaded into memory.

4) Resize Image & Preprocess: The received image is resized to match the input size expected by the model, and any necessary preprocessing steps are applied.

5) Model Prediction: The preprocessed image is passed through the loaded model to make a prediction.

6)Convert Prediction to Class: The prediction output is converted from numerical class probabilities to human-readable class labels using the label encoder.

7) Return Prediction: The predicted class label is returned as the response to the API request.
